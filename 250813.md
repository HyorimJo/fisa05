# 8/13 ELK 6일차

## Keywords
Logstash Filebeat

***

## Keeps
폴더를 왔다갔다 하니까 너무 복잡해요

## Problem
지피티야 grok을 부탁해

## Try
실행시켜야 할 파일이 한 두개가 아님,,


## 알아둘 내용

## 1. Logstash
- 실시간 파이프라인 기능을 가진 오픈소스 데이터 수집 엔진
- Logstash는 서로 다른 소스의 데이터를 탄력적으로 통합하고 사용자가 선택한 목적지로 데이터를 정규화할 수 있음

## 2. Grok Pattern
- Logstach filter를 통해 비정형 데이터를 정형 데이터로 바꿀 수 있음. 이때 정규식을 이용하여 정형화 하는 방법이 Grok Pattern
- Dev Tools → Grok Debbuger에서 간단하게 확인 가능
- 문법
    - %{SYNTAX:SEMANTIC}
    - SYNTAX : Input에서 감지해야 하는 정규식 패턴
    - SEMANTIC : 감지된 패턴을 할당할 logstash 변수

- 주요 필터 플러그인
    - `grok`: 정규식 기반 데이터 파싱
    - `mutate`: 필드 수정, 변환, 삭제 등
    - `date`: 날짜 형식 변환 및 타임스탬프 조정
    - `geoip`: IP 주소 기반 위치 정보 추출
    - `json`: JSON 데이터 처리
    - `csv`: CSV 데이터 처리 및 필드 매핑
    - `drop`: 불필요한 이벤트 제거

## 3. Filebeat
- 데이터들을 서버에서 다른 곳으로 전송하기 위한 오픈소스로 로그 데이터를 수집하여 전달하고 중앙화하기 위해 많이 사용됩니다.
- 역할: 지정한 로그파일 또는 위치를 모니터링(변화 감지) 하고 그 로그 이벤트를 수집해 Elasticsearch 또는 logstash로 전달합니다.

## 실습
```
# logstash-pipeline-5.conf
input{
	file{
		path => "C:/ITStudy/05_elk/fisa05-elk01/test2.log" # 경로 지정시 자바의 표현법으로 /로 바꾸기
		start_position => "beginning"
	}
}

filter {
	grok{
		match => {"message" => "%{MONTHNUM:month}월 %{MONTHDAY:day}, %{YEAR:year} %{HOUR:hour}:%{MINUTE:minute}:%{SECOND:second} (?<time>[가-힣]{2}) %{DATA:class} log"}
		match => {"message" => "정보:%{DATA:info}"}
	}
}



output{
	elasticsearch {
	hosts => ["http://127.0.0.1:9200"]
	index => "logs_multiline-%{+YYYY.MM.dd}"
	data_stream => false 
  }
}
```

- 여러 개의 파이프라인을 동시에 -> pipelines.yml
```
# -pipeline.id: 파이프라인 이름
#  path.config 파이프라인의 config 경로 - 상대경로롤 config를 작성합니다.
# 같은 파일을 바라보도록 파이프라인을 여러개 작성하면 그중에 1개만 작동합니다.
# log파일의 마지막 글자 위치(offset)를 기억했다가 그 다음 입력을 받기 때문
- pipeline.id: my-pipe-1
  path.config: "./config/logstash-pipeline-4.conf"

- pipeline.id: my-pipe-2
  path.config: "./config/logstash-pipeline-5.conf" # path의 상대경로는 내가 해당 파일을 실행할 경로 기준

- pipeline.id: my-pipe-3
  path.config: "./config/logstash-pipeline-from-server.conf"
```